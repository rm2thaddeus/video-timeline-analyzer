---
description: cursor rules
globs: .cursorrc.json
alwaysApply: false
---
# Cursor Project Rules for Video Timeline Analyzer (De-Novo Branch)

## 1. Code Structure & Modularity
- All code must be organized into small, reusable modules.
- Each module must have a clear, single responsibility.
- No code duplication; shared logic must be factored into helpers or utilities.

## 2. Documentation & Comments
- Every file must start with a structured comment block (purpose, latest changes, key logic, expected path, reasoning).
- All public functions/classes must have docstrings with input/output types and descriptions.
- Inline comments must explain logic, not just describe code.
- All scientific/algorithmic choices must be justified in comments or documentation.
- **If any troubleshooting or debugging step is performed in a file, a detailed reasoning log must be added to the comment section at the start of the file, documenting all troubleshooting steps. This log must be committed and tracked at all times.**

## 3. Testing & Validation
- All new code must include unit tests.
- Tests must be reproducible and not depend on external state.
- Use pytest as the default testing framework.
- All code must pass tests before merging.

## 4. Environment & Dependency Management
- All code must run in a virtual environment (venv or conda).
- Dependencies must be listed in requirements.txt or environment.yml.
- No hardcoded paths; use configuration files or environment variables.
- Sensitive files (e.g., .env) must never be overwritten without explicit user confirmation.

## 5. Git & GitHub Workflow (with explicit hand-holding and demonstration)
- All work must be done in feature branches; no direct commits to main or de-novo.
- Only working, tested code may be merged.
- Commit messages must be clear, descriptive, and follow the conventional commits style (e.g., feat:, fix:, docs:, chore:).
- Pull requests must reference relevant issues and be reviewed before merging.
- **All Git/GitHub actions (staging, committing, pushing) must be explained step-by-step, with explicit instructions and hand-holding, as the user is not a coder.**
- **The system must perform all Git/GitHub actions and explain the reasoning for each step, so the user can learn by seeing the process in action.**
- Whenever the user requests a GitHub or version control action, provide clear, actionable steps, perform the action, and confirm the result.
- **Always keep track of and stage all proposed changes, except for files that are likely to be one-off scripts. One-off scripts should be removed after execution and not committed.**

## 6. Scientific Rigor & Reproducibility (with DataFrame tracking)
- All processing steps must be deterministic and parameterized.
- All parameters and random seeds must be logged and version-controlled.
- DataFrames and intermediate results must be persisted for reproducibility.
- All alignment and data fusion logic must be explicitly documented.
- **Once the DataFrame structure is finalized, it must be version-controlled. All changes to the DataFrame structure must be tracked, documented, and justified, including which pipeline components affect it.**

## 7. Data Management & Privacy
- All data must be handled in accordance with privacy and ethical guidelines.
- No personal or sensitive data may be committed to the repository.
- Data exports must be anonymized or stripped of sensitive information.

## 8. Rule Evolution
- Project rules must be reviewed and updated at the start of each major phase.
- All rule changes must be documented and approved by project stakeholders.

## 9. Docker Build Data Cleanup & Disk Management
- To ensure disk space is carefully managed, systematically remove data from failed, unnecessary, or outdated Docker builds, images, containers, and caches.
- Follow these CLI steps for safe, reproducible cleanup:

### Step-by-Step Instructions

#### 1. Remove Stopped Containers
```
docker container prune -f
```
_Removes all stopped containers._

#### 2. Remove Unused Images (Dangling and Unreferenced)
```
docker image prune -a -f
```
_Removes all images not referenced by any container (including failed builds)._

#### 3. Remove Unused Volumes
```
docker volume prune -f
```
_Removes all unused volumes (often left by failed builds)._

#### 4. Remove Unused Networks
```
docker network prune -f
```
_Removes all unused networks._

#### 5. Remove Build Cache
```
docker builder prune -a -f
```
_Removes all unused build cache data (can be substantial after many builds)._

#### 6. Full System Prune (Optional, Most Aggressive)
```
docker system prune -a --volumes -f
```
_Removes all unused data: containers, images, volumes, and networks. Use with caution!_

### Best Practices
- Run these commands regularly (e.g., after CI/CD runs, or when disk space is low).
- Always review what will be deleted (use `docker system df` to see disk usage).
- Automate cleanup in CI/CD pipelines if possible, but never on production systems without review.
- Document all cleanup actions in project logs for reproducibility and auditability.

### Troubleshooting
- If disk space is not reclaimed, ensure Docker Desktop/Engine is restarted.
- If using WSL2, compact the `.vhdx` file after cleanup for actual disk space recovery (see separate instructions).

### Scientific Rigor
- All cleanup steps must be logged and version-controlled if run as part of a pipeline.
- No manual deletion of files outside Docker CLI unless explicitly documented and justified.

### Reference
- [Docker Disk Usage Documentation](https://docs.docker.com/config/pruning/)
- [Docker System Prune](https://docs.docker.com/engine/reference/commandline/system_prune/)

# End of Cursor Project Rules
